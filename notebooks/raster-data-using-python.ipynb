{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Working with raster data in python\n",
    "\n",
    "\n",
    "## Table of Contents\n",
    "\n",
    "1. [About the dataset](#dataset)<br>\n",
    "2. [Part 1 - Weather maps with netCDF4 and matplotlib](#part1)<br>\n",
    "    2.1. [Import packages](#import1)<br>\n",
    "    2.2. [Load gridded data with netCDF4](#load1)<br>\n",
    "    2.3. [Create a global map of the average temperature in January using matplotlib](#map1)<br>\n",
    "\n",
    "3. [Part 2 - Weather maps with xarray and Cartopy](#part2)<br>\n",
    "    3.1. [Import packages](#import2)<br>\n",
    "    3.2. [Load gridded data with xarray](#load2)<br>\n",
    "    3.3. [Create maps using xarray](#map21)<br>\n",
    "    3.4. [Create maps using Cartoid](#map22)<br>\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"dataset\"></a>\n",
    "## About the dataset\n",
    "\n",
    "With the gridded data from [CRU](http://www.cru.uea.ac.uk/data/) you will learn how to work with gridded historical data. \n",
    "\n",
    "The [dataset](https://crudata.uea.ac.uk/cru/data/temperature/#datdow) contains a 5&deg; by 5&deg; grid with absolute temperatures from 1961 to 1990. The data is represented in a [NetCDF](https://pro.arcgis.com/en/pro-app/help/data/multidimensional/what-is-netcdf-data.htm) format.\n",
    "\n",
    "Download the following file, and store it locally or in object-store when working on the [IBM Data Science Experience](https://datascience.ibm.com/) :\n",
    "\n",
    "* https://crudata.uea.ac.uk/cru/data/temperature/absolute.nc\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part1\"></a>\n",
    "## Part 1 -  Weather maps with netCDF4 and matplotlib\n",
    "\n",
    "\n",
    "In the first half of this tutorial, we will see how to use Python's [netCDF4](https://unidata.github.io/netcdf4-python/netCDF4/index.html) module to extract data from the dataset. \n",
    "\n",
    "\n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"import1\"></a>\n",
    "### 1. Import packages\n",
    "\n",
    "Following is the explicit list of imports that we used through this notebook.  "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests, json\n",
    "from io import StringIO\n",
    "from netCDF4 import Dataset\n",
    "import numpy as np\n",
    "import scipy\n",
    "import matplotlib\n",
    "from pylab import *\n",
    "from mpl_toolkits.basemap import Basemap, addcyclic, shiftgrid\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first import the dataset with a helper function that uses the project token created per instructions mentioned above. Import the `absolute.nc` file locally or add the below code by clicking on `Insert to code` below the file under the file in object-store. Then load the data and explore the variables and dimensions of the file. \n",
    "\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# define the helper function \n",
    "def download_file_to_local(project_filename, local_file_destination=None, project=None):\n",
    "    \"\"\"\n",
    "    Uses project-lib to get a bytearray and then downloads this file to local.\n",
    "    Requires a valid `project` object.\n",
    "    \n",
    "    Args:\n",
    "        project_filename str: the filename to be passed to get_file\n",
    "        local_file_destination: the filename for the local file if different\n",
    "        \n",
    "    Returns:\n",
    "        0 if everything worked\n",
    "    \"\"\"\n",
    "    \n",
    "    project = project\n",
    "    \n",
    "    # get the file\n",
    "    print(\"Attempting to get file {}\".format(project_filename))\n",
    "    _bytes = project.get_file(project_filename).read()\n",
    "    \n",
    "    # check for new file name, download the file\n",
    "    print(\"Downloading...\")\n",
    "    if local_file_destination==None: local_file_destination = project_filename\n",
    "    \n",
    "    with open(local_file_destination, 'wb') as f: \n",
    "        f.write(bytearray(_bytes))\n",
    "        print(\"Completed writing to {}\".format(local_file_destination))\n",
    "        \n",
    "    return 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_file_to_local('absolute.nc', project=project)\n",
    "cfile = \"absolute.nc\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load1\"></a>\n",
    "### 2. Load gridded data with netCDF4\n",
    "\n",
    " We then use netCDF4's *Dictionary* collection to analyse the data and its relations between the fields that consitute the netCDF file. "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = Dataset(cfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "To extract the data model version of the netCDF file, we use the *data_model* variable is used. The data model can be one of NETCDF3_CLASSIC, NETCDF4, NETCDF4_CLASSIC, NETCDF3_64BIT_OFFSET OR NETCDF3_63BIT_DATA.\n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.data_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*dimensions* returns a dictionary with variables names from the dataset mapped to instances of the Dimensions class. It provides the name of the variable along with its size."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(dataset.dimensions)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*variables* returns a dictionary that maps the variable names from the dataset as instances of *Variable* class."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(dataset.variables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below is an example of how variables from the dataset can be accessed as keys of the dictionary returned in the line above. "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lons = dataset.variables['lon'][:] \n",
    "print(\"Shape of longitude data : \",np.shape(lons))\n",
    "\n",
    "lats = dataset.variables['lat'][:] \n",
    "print(\"Shape of latitude data : \",np.shape(lats))\n",
    "\n",
    "time = dataset.variables['time'][:] \n",
    "print(\"Shape of time data : \",np.shape(time))\n",
    "\n",
    "temperature = dataset.variables['tem'][:,:,:]\n",
    "print(\"Shape of temperature data : \",np.shape(temperature))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"map1\"></a>\n",
    "### 3. Create a global map of the average temperature in January using matplotlib\n",
    "\n",
    "\n",
    "We will now see how matplotlib and its extensions can be used to plot 2D maps in Python. Here we use the matplotlib [basemap](https://matplotlib.org/basemap/users/intro.html) toolkit. To map the points on a 2D surface, basemap supports 24 different types of [projections](https://matplotlib.org/basemap/users/mapsetup.html). In this example Miller Projections is used. Miller projections are generally used for wall maps rather than as navigational maps. Details of Miller projections can be found [here](https://matplotlib.org/basemap/users/mill.html). llcrnrlon, llcrnrlat refer to longitude and latitude of lower left hand corner of the desired map domain(degrees) respectively.  urcrnrlon, urcrnrlat refer to longitude and latitude of lower right hand corner of the desired map domain(degrees) respectively. "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define the area to plot and projection to use\n",
    "m =\\\n",
    "Basemap(llcrnrlon=-180,llcrnrlat=-60,urcrnrlon=180,urcrnrlat=80,projection='mill')\n",
    "\n",
    "# covert the latitude, longitude and temperatures to raster coordinates to be plotted\n",
    "t1=temperature[0,:,:]\n",
    "t1,lon=addcyclic(t1,lons)\n",
    "january,longitude=shiftgrid(180.,t1,lon,start=False)\n",
    "x,y=np.meshgrid(longitude,lats)\n",
    "px,py=m(x,y)\n",
    "\n",
    "palette=cm.RdYlBu_r\n",
    "rmin=-30.\n",
    "rmax=30.\n",
    "ncont=20\n",
    "dc=(rmax-rmin)/ncont\n",
    "vc=arange(rmin,rmax+dc,dc)\n",
    "pal_norm=matplotlib.colors.Normalize(vmin = rmin, vmax = rmax, clip = False)\n",
    "\n",
    "m.drawcoastlines(linewidth=0.5)\n",
    "m.drawmapboundary(fill_color=(1.0,1.0,1.0))\n",
    "cf=m.pcolormesh(px, py, january, cmap = palette)\n",
    "cbar=colorbar(cf,orientation='horizontal', shrink=0.95)\n",
    "cbar.set_label('Mean Temperature in January')\n",
    "tight_layout()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*addcyclic* adds a column of longitude to a set of data. In the code below we see that the longitude array is added to an array containing temperature entries. *shiftgrid* moves all longitudes and data east or west. The *meshgrid* method returns co-ordinate matrictes from one dimentional coordinate arrays. In the code below, we use meshgrid to convert longitude and latitude arrays into x and y coordinate arrays. "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"part2\"></a>\n",
    "## Part 2 - Weather maps with xarray and Cartopy\n",
    "\n",
    "In the second half of tutorial, we will see how to use [xarray](http://xarray.pydata.org/en/stable/) to process the netCDF data. xarray is useful with analysing multidimensional arrays. It shares functionalities from pandas and NumPy. xarray has proven to be a robust library to handle netCDF files. \n"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"import2\"></a>\n",
    "### 1. Import packages\n",
    "\n",
    "Following snippet shows the required imports that needs to be done to be able to run the notebook. "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "import matplotlib.pyplot as plt\n",
    "import cartopy.crs as ccrs\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"load2\"></a>\n",
    "### 2. Load gridded data with xarray\n",
    "\n",
    "We then open and load the dataset using xarray. "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = xr.open_dataset(cfile)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "xarray supports the following data structures : \n",
    "\n",
    "- *DataArray* which is a multidimensional array \n",
    "-  *Dataset* which is a dictionaty of multiple DataArray objects.\n",
    "\n",
    " netCDF data is represented as a Dataset in xarray. "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*dims* returns the value of the x, y and z coordinates. "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.dims"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*coords* returns just the coordinates section from the *values* variable we saw above."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.coords"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Since xarray is an extension to pandas, it offers a method which enables us to convert the dataset to a dataframe. "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = dataset.to_dataframe()\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"map21\"></a>\n",
    "### 3. Create maps using xarray\n",
    "xarray also supports plotting fuctionalities by extending the *matplotlib* library. DataArray objects can be plotted using xarray libraries. To plot Dataset objects, the relevant DataArrays or dimensions needs to be accessed. "
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.mean(dim=['time','lon']).to_dataframe().plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.tem[0].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"map22\"></a>\n",
    "### 4. Create maps using Cartopy \n",
    "\n",
    "[Cartopy](https://scitools.org.uk/cartopy/docs/latest/) is one of the several  plotting applications that are compatible with xarray. Few others are Seaborn, HoloViews and GeoViews.\n",
    "\n",
    "Below is a simple example of using cartopy to create visualizations. We compare the Molleweide projection vs the Miller projection. A complete list of projections can be found [here](https://scitools.org.uk/cartopy/docs/latest/crs/projections.html)"
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = plt.figure(figsize=(14,5))\n",
    "plt.title(\"Molleweide VS Miller Projection for the month of January\", fontsize=20)\n",
    "plt.axis('off')\n",
    "ax1 = f.add_subplot(1,2,1, projection = ccrs.Mollweide())\n",
    "ax2 = f.add_subplot(1,2,2, projection = ccrs.Miller())\n",
    "ax1.coastlines()\n",
    "ax1.gridlines()\n",
    "ax2.coastlines()\n",
    "ax2.gridlines()\n",
    "\n",
    "dataset.tem[0].plot(ax=ax1, transform=ccrs.PlateCarree())\n",
    "dataset.tem[0].plot(ax=ax2, transform=ccrs.PlateCarree())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following is a heat map comparing the intensity of temperatures between the month of January and June."
   ],
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "proj = ccrs.Miller()\n",
    "jan_june = dataset.tem.isel(time=[0,5])\n",
    "months = ['January','June']\n",
    "i = 0\n",
    "\n",
    "p = jan_june.plot(transform=ccrs.PlateCarree(),\n",
    "             col='time', col_wrap=2, \n",
    "             aspect=dataset.dims['lon'] / dataset.dims['lat'],\n",
    "             subplot_kws={'projection': proj})\n",
    "\n",
    "\n",
    "for ax in p.axes.flat:\n",
    "    ax.coastlines()\n",
    "    ax.gridlines()\n",
    "    ax.set_title(months[i])\n",
    "    i = i+1\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Author\n",
    "Margriet Groenendijk is a Data & AI Developer Advocate for IBM. She develops and presents talks and workshops about data science and AI. She is active in the local developer communities through attending, presenting and organising meetups. She has a background in climate science where she explored large observational datasets of carbon uptake by forests during her PhD, and global scale weather and climate models as a postdoctoral fellow. \n",
    "\n",
    "Samaya Madhavan is an Advisory Software Engineer with IBM where she currently publishes content that are related to machine learning and deep learning. She is also a full stack software developer, experienced in offering AI based solutions within the healthcare domain. Samaya has her Bachelor of Engineering in Computer Science from College of Engineering, Guindy and her Master of Science in Computer Science from University of Texas at Arlington. She is an ardent learner and a very passionate algorithm solver.\n",
    "\n",
    "Copyright © 2019 IBM. This notebook and its source code are released under the terms of the MIT License."
   ],
   "execution_count": null,
   "outputs": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}